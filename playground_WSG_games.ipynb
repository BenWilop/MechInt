{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenWilop/MechInt/blob/main/playground_WSG_games.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_iwAU-_BWEL"
      },
      "source": [
        "# Installs + Github + Google Colab Things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwALlfIaBVWX",
        "outputId": "5404776e-e4a2-426b-a05d-fefd2028f038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88JvcAiIBYDh",
        "outputId": "dbc9e5b3-a23e-4494-8d87-7e97fc44e0d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get install git\n",
        "!pip install python-dotenv --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V887fWJPBYKB",
        "outputId": "5e529efd-c5f0-4089-fb72-886950bf3dff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbenwilop\u001b[0m (\u001b[33mbenwilop-rwth-aachen-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'WSG_games'...\n",
            "remote: Enumerating objects: 185, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (107/107), done.\u001b[K\n",
            "remote: Total 185 (delta 100), reused 152 (delta 67), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (185/185), 159.15 KiB | 17.68 MiB/s, done.\n",
            "Resolving deltas: 100% (100/100), done.\n",
            "Not in a git repository.\n"
          ]
        }
      ],
      "source": [
        "import getpass\n",
        "import dotenv\n",
        "import wandb\n",
        "import os\n",
        "dotenv.load_dotenv(os.path.join('/content/drive/MyDrive/Colab Notebooks', 'vscode-ssh.env.txt'))\n",
        "password = os.getenv('PASSWORD')\n",
        "github_access_token = os.getenv('GITHUB_ACCESS_TOKEN')\n",
        "api_key = os.getenv('WANDB_API_KEY')\n",
        "wandb.login(key=api_key)\n",
        "\n",
        "repo_url = f\"https://github.com/BenWilop/WSG_games\"\n",
        "\n",
        "!git clone $repo_url\n",
        "!git lfs pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aduty50XOBB-"
      },
      "source": [
        "Script to push / pull / pull + push from GitHub. (Seems to only work for files in the folder, the notebook itself can be pushed by Strg+S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112,
          "referenced_widgets": [
            "d19bdd5f4dc24b449367d9097f851c7a",
            "d570db71c3384b25abaf38b9792c0a4f",
            "3acc784ecb63411b8aca45d1f0842bcb",
            "87e3c17034aa41bb8ef52596cb5e7b74",
            "a690f211f08e4416a841e2fd93fd6d75",
            "1ca2558fdf9d45dfbc7f8e6e2d7d4b39",
            "c6a8a272a285403fb8f1daa6209af4e9",
            "fcf72a82a1e54f59ad456b175a9c303f",
            "99e5436f186a493ab3e8200b77ff6e84",
            "179f5f55687f496e90eb069cb44be4d5",
            "8ecefc0372ab41ae9ad3a1aae7ff871e"
          ]
        },
        "id": "Jkz572y3K4kF",
        "outputId": "71bd0223-c704-4e85-b92a-f0cd3a61df9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='Updated Python scripts in Google Colab', description='Commit:', layout=Layout(width='70%'), placeh‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d19bdd5f4dc24b449367d9097f851c7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='Action:', options=('Pull', 'Push', 'Pull & Push'), value='Pull')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87e3c17034aa41bb8ef52596cb5e7b74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Button(button_style='success', description='Run Git Commands üöÄ', style=ButtonStyle())"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6a8a272a285403fb8f1daa6209af4e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "179f5f55687f496e90eb069cb44be4d5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title # Push and Pull Repo to Git\n",
        "import subprocess\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# Configuration\n",
        "GIT_EMAIL = \"ben.wilop@web.de\"\n",
        "GIT_NAME = \"BenWilop\"\n",
        "REPO_DIR = \"/content/WSG_games\"  # Ensure this is the correct path\n",
        "\n",
        "# UI Elements\n",
        "commit_message = widgets.Text(\n",
        "    value=\"Updated Python scripts in Google Colab\",\n",
        "    placeholder=\"Enter commit message...\",\n",
        "    description=\"Commit:\",\n",
        "    layout=widgets.Layout(width=\"70%\")\n",
        ")\n",
        "\n",
        "action_buttons = widgets.ToggleButtons(\n",
        "    options=[\"Pull\", \"Push\", \"Pull & Push\"],\n",
        "    description=\"Action:\"\n",
        ")\n",
        "\n",
        "run_button = widgets.Button(\n",
        "    description=\"Run Git Commands üöÄ\",\n",
        "    button_style=\"success\"\n",
        ")\n",
        "\n",
        "output = widgets.Output()\n",
        "\n",
        "# Helper function to run a command in REPO_DIR and print its output\n",
        "def run_cmd(cmd, cwd=REPO_DIR):\n",
        "    try:\n",
        "        result = subprocess.run(cmd, shell=True, cwd=cwd, capture_output=True, text=True)\n",
        "        print(f\"üíª $ {cmd}\")\n",
        "        if result.stdout:\n",
        "            print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error running {cmd}: {e}\")\n",
        "\n",
        "def run_git_commands(b):\n",
        "    with output:\n",
        "        clear_output()\n",
        "        print(f\"üìÇ Using repository directory: {REPO_DIR}\\n\")\n",
        "\n",
        "        # Set global Git config\n",
        "        print(\"üîß Setting Git configuration:\")\n",
        "        run_cmd(f'git config --global user.email \"{GIT_EMAIL}\"')\n",
        "        run_cmd(f'git config --global user.name \"{GIT_NAME}\"')\n",
        "\n",
        "        # Added\n",
        "        remote_url = f\"https://{GIT_NAME}:{github_access_token}@github.com/BenWilop/WSG_games.git\"\n",
        "        # print(\"/////////////////////\", remote_url)\n",
        "        run_cmd(f'git remote set-url origin {remote_url}')\n",
        "\n",
        "        # Show current Git status\n",
        "        print(\"\\nüìä Current Git status:\")\n",
        "        run_cmd(\"git status\")\n",
        "\n",
        "        action = action_buttons.value\n",
        "        commit_msg = commit_message.value.strip() or \"Updated Python scripts in Google Colab\"\n",
        "\n",
        "        # If pull is selected, perform git pull\n",
        "        if \"Pull\" in action:\n",
        "            print(\"\\n‚¨áÔ∏è Pulling latest changes from GitHub:\")\n",
        "            run_cmd(\"git pull --rebase origin main\")\n",
        "\n",
        "        # If push is selected, stage, commit, and push changes\n",
        "        if \"Push\" in action:\n",
        "            print(\"\\nüì§ Staging changes:\")\n",
        "            run_cmd(\"git add .\")\n",
        "            print(\"‚úçÔ∏è Committing changes:\")\n",
        "            run_cmd(f'git commit -m \"{commit_msg}\"')\n",
        "            print(\"üöÄ Pushing changes to GitHub:\")\n",
        "            run_cmd(\"git push origin main\")\n",
        "\n",
        "        print(\"\\n‚úÖ Done!\")\n",
        "\n",
        "# Link the button click event to our function\n",
        "run_button.on_click(run_git_commands)\n",
        "\n",
        "# Display the UI elements\n",
        "display(commit_message, action_buttons, run_button, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9HqdWFhBJfa"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ5zY6W6xOP5",
        "outputId": "40e52c4e-44c6-4279-da18-b3a2579ceae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.15.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.3.0)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.8.1)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.38-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (13.9.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=2.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.67.1)\n",
            "Requirement already satisfied: transformers>=4.43 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.48.3)\n",
            "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer_lens)\n",
            "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.11/dist-packages (from transformer_lens) (0.19.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.7.1->transformer_lens) (3.11.13)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading wadler_lindig-0.1.3-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->transformer_lens) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.2->transformer_lens)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43->transformer_lens) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.43->transformer_lens) (0.21.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (4.25.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.13.5->transformer_lens) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.13.5->transformer_lens) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.2)\n",
            "Downloading transformer_lens-2.15.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.2.38-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.3-py3-none-any.whl (20 kB)\n",
            "Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers-stream-generator\n",
            "  Building wheel for transformers-stream-generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=606b681cf24f683f49945fb5cea5a2ccf74aebb55fd9d94baabbd594d61fd01a\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
            "Successfully built transformers-stream-generator\n",
            "Installing collected packages: better-abc, xxhash, wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fancy-einsum, dill, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, jaxtyping, nvidia-cusolver-cu12, datasets, transformers-stream-generator, transformer_lens\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.3.2 dill-0.3.8 fancy-einsum-0.0.3 jaxtyping-0.2.38 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformer_lens-2.15.0 transformers-stream-generator-0.0.5 wadler-lindig-0.1.3 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformer_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AggaQuEUBk_5",
        "outputId": "20593950-8f6a-477e-9b6f-a5928703a485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/WSG_games/')\n",
        "print(\"device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uV6cMqvSvaBY"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import cross_entropy, softmax\n",
        "from torch import Tensor\n",
        "from jaxtyping import Float\n",
        "from tqdm import tqdm\n",
        "from transformer_lens import HookedTransformerConfig, HookedTransformer\n",
        "import json\n",
        "from typing import Callable, Any\n",
        "import einops\n",
        "import time\n",
        "import uuid\n",
        "import glob\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import torch.nn as nn\n",
        "\n",
        "from wsg_games.tictactoe.evals import *\n",
        "from wsg_games.tictactoe.data import *\n",
        "from wsg_games.tictactoe.game import *\n",
        "\n",
        "device = t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-WZi6lEq1sA"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja80xiGclrkX",
        "outputId": "74362257-7041-4126-ada0-d429148c34ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape Data:    torch.Size([255168, 10])\n",
            "Shape Random:  torch.Size([255168, 10, 10])\n",
            "Shape Weak:    torch.Size([255168, 10, 10])\n",
            "Shape Strong:  torch.Size([255168, 10, 10])\n"
          ]
        }
      ],
      "source": [
        "# tictactoe_data = calculate_tictactoe_data()\n",
        "tictactoe_data = cache_tictactoe_data('/content/drive/MyDrive/WSG_games/data/tictactoe_data.pkl')\n",
        "\n",
        "print(\"Shape Data:   \", tictactoe_data.games_data.shape)\n",
        "print(\"Shape Random: \", tictactoe_data.random_move_labels.shape)\n",
        "print(\"Shape Weak:   \", tictactoe_data.weak_goals_labels.shape)\n",
        "print(\"Shape Strong: \", tictactoe_data.strong_goals_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxZx1rEDmKtH",
        "outputId": "af41cfbb-4225-4acf-a09d-0c840996a2a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evals Random:  {'weak_accuracy': 0.6751543879508972, 'strong_accuracy': 0.6257853507995605, 'illegal_move_chance': 0.0}\n",
            "Evals Weak:    {'weak_accuracy': 1.0, 'strong_accuracy': 0.4728437662124634, 'illegal_move_chance': 0.0}\n",
            "Evals Strong:  {'weak_accuracy': 0.5391287207603455, 'strong_accuracy': 1.0, 'illegal_move_chance': 0.0}\n"
          ]
        }
      ],
      "source": [
        "print(\"Evals Random: \", evaluate_predictions(tictactoe_data.random_move_labels, tictactoe_data))\n",
        "print(\"Evals Weak:   \", evaluate_predictions(tictactoe_data.weak_goals_labels, tictactoe_data))\n",
        "print(\"Evals Strong: \", evaluate_predictions(tictactoe_data.strong_goals_labels, tictactoe_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvItakEVbU8U",
        "outputId": "61f3dd1c-e830-4f6a-d976-afad2e3b28b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropy Random:  1.2616221904754639\n",
            "Entropy Weak:    0.6724082827568054\n",
            "Entropy Strong:  0.5945572853088379\n"
          ]
        }
      ],
      "source": [
        "# These are the minimal achievable CE losses.\n",
        "import torch.distributions as dist\n",
        "\n",
        "def entropy(labels: t.Tensor) -> float:\n",
        "    distribution = dist.Categorical(probs=labels)\n",
        "    ent = distribution.entropy()\n",
        "    return ent.mean().item()\n",
        "\n",
        "print(\"Entropy Random: \", entropy(tictactoe_data.random_move_labels))\n",
        "print(\"Entropy Weak:   \", entropy(tictactoe_data.weak_goals_labels))\n",
        "print(\"Entropy Strong: \", entropy(tictactoe_data.strong_goals_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoCX7cACxBLY",
        "outputId": "7d55f619-165f-4d42-8d53-2a1fac405dd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape Train:  torch.Size([204134, 10])\n",
            "Shape Test:   torch.Size([51034, 10])\n"
          ]
        }
      ],
      "source": [
        "tictactoe_train_data, tictactoe_test_data = train_test_split_tictactoe(tictactoe_data, 0.8, device, 1234)\n",
        "print(\"Shape Train: \", tictactoe_train_data.games_data.shape)\n",
        "print(\"Shape Test:  \", tictactoe_test_data.games_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8kIUD9u4_QGk"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def sample_hard_labels_from_soft(soft_labels: t.Tensor, num_samples: int = 5) -> t.Tensor:\n",
        "    n_games, game_length, n_tokens = soft_labels.shape\n",
        "    soft_labels_flat = soft_labels.view(-1, n_tokens)\n",
        "    sampled_indices = t.multinomial(soft_labels_flat, num_samples=num_samples, replacement=True)\n",
        "\n",
        "    one_hot_samples = F.one_hot(sampled_indices, num_classes=n_tokens).float()\n",
        "    one_hot_samples = one_hot_samples.view(n_games, game_length, num_samples, n_tokens)\n",
        "    one_hot_samples = one_hot_samples.permute(0, 2, 1, 3)\n",
        "    new_hard_labels = one_hot_samples.reshape(n_games * num_samples, game_length, n_tokens)\n",
        "    return new_hard_labels\n",
        "\n",
        "def create_hard_label_tictactoe_data(data: TicTacToeData, num_samples: int = 5, random_seed: int = 4567) -> TicTacToeData:\n",
        "    t.manual_seed(random_seed)\n",
        "\n",
        "    new_games_data = data.games_data.repeat_interleave(num_samples, dim=0)\n",
        "    new_random_move_labels = sample_hard_labels_from_soft(data.random_move_labels, num_samples=num_samples)\n",
        "    new_weak_goals_labels  = sample_hard_labels_from_soft(data.weak_goals_labels, num_samples=num_samples)\n",
        "    new_strong_goals_labels = sample_hard_labels_from_soft(data.strong_goals_labels, num_samples=num_samples)\n",
        "\n",
        "    return TicTacToeData(\n",
        "        games_data=new_games_data,\n",
        "        random_move_labels=new_random_move_labels,\n",
        "        weak_goals_labels=new_weak_goals_labels,\n",
        "        strong_goals_labels=new_strong_goals_labels\n",
        "    )\n",
        "\n",
        "# print(tictactoe_train_data.weak_goals_labels.shape)\n",
        "# print(tictactoe_train_data.weak_goals_labels[:-3,:-3,:-3])\n",
        "# tictactoe_train_data = create_hard_label_tictactoe_data(tictactoe_train_data, num_samples=5)\n",
        "# tictactoe_test_data = create_hard_label_tictactoe_data(tictactoe_test_data, num_samples=5)\n",
        "# print(tictactoe_train_data.weak_goals_labels.shape)\n",
        "# print(tictactoe_train_data.weak_goals_labels[:-3,:-3,:-3])\n",
        "\n",
        "tictactoe_train_data.weak_goals_labels = tictactoe_train_data.random_move_labels\n",
        "tictactoe_test_data.weak_goals_labels = tictactoe_test_data.random_move_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuRcWagTqzSr"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLl-6o7fjzfS"
      },
      "outputs": [],
      "source": [
        "raise Exception()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_6vzd1Lrwt5"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjketwo1ipxE",
        "outputId": "e1b0ce59-ca1c-4802-c0b2-684540a11051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cuda\n",
            "tiny 2.2 * 10^03\n",
            "Moving model to device:  cuda\n",
            "small 9.6 * 10^03\n",
            "Moving model to device:  cuda\n",
            "medium 1.0 * 10^05\n",
            "Moving model to device:  cuda\n",
            "large 8.0 * 10^05\n",
            "Moving model to device:  cuda\n",
            "huge 8.4 * 10^06\n",
            "Moving model to device:  cuda\n",
            "gigantic 1.0 * 10^08\n"
          ]
        }
      ],
      "source": [
        "training_cfg = {\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 1e-5,\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 64,\n",
        "}\n",
        "\n",
        "model_sizes = {}\n",
        "model_sizes[\"tiny\"]   = {\"n_layers\": 1, \"n_heads\": 1, \"d_model\": 16, \"d_head\": 8, \"d_mlp\": 32}\n",
        "model_sizes[\"small\"] = {\"n_layers\": 1, \"n_heads\": 2, \"d_model\": 32, \"d_head\": 16, \"d_mlp\": 64}\n",
        "model_sizes[\"medium\"] = {\"n_layers\": 2, \"n_heads\": 4, \"d_model\": 64, \"d_head\": 16, \"d_mlp\": 256}\n",
        "model_sizes[\"large\"] = {\"n_layers\": 4, \"n_heads\": 8, \"d_model\": 128, \"d_head\": 16, \"d_mlp\": 512}\n",
        "model_sizes[\"huge\"]   = {\"n_layers\": 8, \"n_heads\": 16, \"d_model\": 256, \"d_head\": 32,  \"d_mlp\": 1024}\n",
        "model_sizes[\"gigantic\"] = {\"n_layers\": 16, \"n_heads\": 32, \"d_model\": 512, \"d_head\": 64, \"d_mlp\": 2048}\n",
        "\n",
        "def get_model_config(size: str):\n",
        "    common_params = {\n",
        "        \"act_fn\": \"relu\",\n",
        "        \"normalization_type\": \"LN\",\n",
        "        \"d_vocab\": 11,\n",
        "        \"d_vocab_out\": 10,\n",
        "        \"n_ctx\": 10,\n",
        "        \"init_weights\": True,\n",
        "        \"device\": \"cuda\",\n",
        "        \"seed\": 1337,\n",
        "    }\n",
        "    specific = model_sizes[size]\n",
        "    return HookedTransformerConfig(**specific, **common_params)\n",
        "\n",
        "def format_integer_scientific(n: float) -> str:\n",
        "    s = f\"{n:.1e}\"\n",
        "    return s.replace(\"e+\", \" * 10^\")\n",
        "\n",
        "def count_parameters(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "for model_size in model_sizes.keys():\n",
        "    cfg = get_model_config(model_size)\n",
        "    mod = HookedTransformer(cfg).to(cfg.device)\n",
        "    n = count_parameters(mod)\n",
        "    print(model_size, format_integer_scientific(n))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rearrange(tensor: Tensor) -> Tensor:\n",
        "    \"\"\"\n",
        "    Flattens the first two dimensions (n_games and game_length) into one.\n",
        "    This converts a tensor of shape [n_games, game_length, n_tokens]\n",
        "    into [n_games * game_length, n_tokens] which is what F.cross_entropy expects.\n",
        "    \"\"\"\n",
        "    return einops.rearrange(tensor, \"batch seq token -> (batch seq) token\")"
      ],
      "metadata": {
        "id": "8tp-gFCjNW3C"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-I_WW83ry7U"
      },
      "source": [
        "### wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JRBuJwAAqk_n"
      },
      "outputs": [],
      "source": [
        "def log_epoch_wandb(logits: Float[Tensor, \"n_games game_length n_tokens\"], data: TicTacToeData, loss_fn, folder) -> None:\n",
        "  res = {}\n",
        "  flat_logits = rearrange(logits)\n",
        "  flat_weak_labels = rearrange(data.weak_goals_labels)\n",
        "  flat_strong_labels = rearrange(data.strong_goals_labels)\n",
        "  flat_random_labels = rearrange(data.random_move_labels)\n",
        "\n",
        "  res = {}\n",
        "  res[folder + 'weak_loss'] = loss_fn(flat_logits, flat_weak_labels).item()\n",
        "  res[folder + 'strong_loss'] = loss_fn(flat_logits, flat_strong_labels).item()\n",
        "  res[folder + 'random_loss'] = loss_fn(flat_logits, flat_random_labels).item()\n",
        "\n",
        "  predictions = softmax(logits, -1)\n",
        "  evaluation = evaluate_predictions(predictions, data)\n",
        "  for metric, value in evaluation.items():\n",
        "    res[folder + metric] = value\n",
        "  wandb.log(res)\n",
        "\n",
        "def log_generating_game_wandb(model, n_samples=20):\n",
        "    samples = sample_games(model, 1, n_samples)\n",
        "    evaluation = eval_model(samples)\n",
        "    res = {}\n",
        "    for metric, value in evaluation.items():\n",
        "      res[\"generative/\" + metric] = value\n",
        "    wandb.log(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZblgAQar1jd"
      },
      "source": [
        "### Train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QnBbOGvJwe83"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def evaluate_model(model, train_data, test_data, loss_fn, n_samples=100):\n",
        "    model.eval()\n",
        "    with t.no_grad():\n",
        "        train_sample = random_sample_tictactoe_data(train_data, n_samples)\n",
        "        train_logits = model(train_sample.games_data)\n",
        "        log_epoch_wandb(train_logits, train_sample, loss_fn, \"train/\")\n",
        "\n",
        "        test_sample = random_sample_tictactoe_data(test_data, n_samples)\n",
        "        test_logits = model(test_sample.games_data)\n",
        "        log_epoch_wandb(test_logits, test_sample, loss_fn, \"test/\")\n",
        "\n",
        "def train_model(project_name: str, experiment_name: str, timestamp: str,\n",
        "                model, goal: Goal, optimizer, loss_fn,\n",
        "                train_data: TicTacToeData, test_data: TicTacToeData,\n",
        "                epochs: int, batch_size: int) -> None:\n",
        "    \"\"\"Log train + test ~ every 1000 datapoints and generation every 50000\"\"\"\n",
        "    log_generating_game_wandb(model)\n",
        "    evaluate_model(model, train_data, test_data, loss_fn)\n",
        "\n",
        "    # Dataloader for minibatches and shuffling\n",
        "    train_dataset = TensorDataset(\n",
        "        train_data.games_data,\n",
        "        train_data.random_move_labels,\n",
        "        train_data.weak_goals_labels,\n",
        "        train_data.strong_goals_labels\n",
        "    )\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    n_datapoints_since_last_evaluation = 0\n",
        "    n_datapoints_since_last_generation_evaluation = 0\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training epochs\", position=0, dynamic_ncols=True):\n",
        "        # -------------------------\n",
        "        # Training Phase (mini-batch loop)\n",
        "        # -------------------------\n",
        "        model.train()\n",
        "        for games, random_labels, weak_labels, strong_labels in tqdm(train_loader, desc=\"Training batches\", leave=False, position=1, dynamic_ncols=True):\n",
        "            match goal:\n",
        "              case Goal.WEAK_GOAL:\n",
        "                  labels = weak_labels\n",
        "              case Goal.STRONG_GOAL:\n",
        "                  labels = strong_labels\n",
        "              case _:\n",
        "                  raise ValueError(f\"Unexpected goal {goal}\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(games)\n",
        "            loss = loss_fn(rearrange(logits),\n",
        "                           rearrange(labels))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            n_datapoints_since_last_evaluation += batch_size\n",
        "            if n_datapoints_since_last_evaluation > 1000:\n",
        "                n_datapoints_since_last_evaluation = 0\n",
        "                evaluate_model(model, train_data, test_data, loss_fn)\n",
        "\n",
        "            n_datapoints_since_last_generation_evaluation += batch_size\n",
        "            if n_datapoints_since_last_generation_evaluation > 50000:\n",
        "                n_datapoints_since_last_generation_evaluation = 0\n",
        "                log_generating_game_wandb(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c7a591f3b841406a9ae4981373a82f98",
            "b1eb62f40f6b45bc826e9cb28d4269eb",
            "b66a301ff9874d1da851bf46b7ba4e57",
            "4b3ceb3d0ceb40d1ae528294b6c8b2b2",
            "0a147ee180694e1db79d87b85e83b70d",
            "d8597b64fc224fec801cd59158f71e59",
            "2b78c21508f74dde97d5641af345e6d0",
            "f6898ccd06fc4968a30443a4893a78ea",
            "d3692294d8d347368865021e3f2112d4",
            "7bb59ead4e224da9842f3545bd64beb4",
            "ea9ee9fcb6a747319de261191e307699",
            "b72874f4af934329a17ad9ff8219f20a",
            "80e3f0edc4b941d7bc9fe12a2db32bbe",
            "93ce3d4eda9f4708b3169dceda073637",
            "ef397fd3d9254e5a866add85caeb6b29",
            "78b7a0d6df4c4b76922971f606ef887e",
            "485cbeffe1834600aa631f1c03fa016a",
            "fb12ed9346ea4051aff80cef91f539d6",
            "66dcb91d824f4e9e996870ce7294c642",
            "13ae7ea679db46769e5795b2d4f6b2aa",
            "1515c612d93145b3b55dfd8e2ef65903",
            "59c9b22f5d8b4257b8184d511b204e08"
          ]
        },
        "id": "szlDLZgl1ist",
        "outputId": "4c8d6565-357f-455a-8352-f6786cdd15d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([204134, 10, 10])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>generative/_check_if_illegal_moves</td><td>‚ñÅ</td></tr><tr><td>generative/_check_played_after_game_ends</td><td>‚ñÅ</td></tr><tr><td>generative/_check_played_repeat_moves</td><td>‚ñÅ</td></tr><tr><td>generative/inappropriate_end_state</td><td>‚ñÅ</td></tr><tr><td>test/illegal_move_chance</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/random_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/strong_accuracy</td><td>‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>test/strong_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/weak_accuracy</td><td>‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>test/weak_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/illegal_move_chance</td><td>‚ñà‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/random_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/strong_accuracy</td><td>‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>train/strong_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/weak_accuracy</td><td>‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/weak_loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>generative/_check_if_illegal_moves</td><td>1</td></tr><tr><td>generative/_check_played_after_game_ends</td><td>0</td></tr><tr><td>generative/_check_played_repeat_moves</td><td>1</td></tr><tr><td>generative/inappropriate_end_state</td><td>0.75</td></tr><tr><td>test/illegal_move_chance</td><td>0.07641</td></tr><tr><td>test/random_loss</td><td>1.39338</td></tr><tr><td>test/strong_accuracy</td><td>0.668</td></tr><tr><td>test/strong_loss</td><td>1.37815</td></tr><tr><td>test/weak_accuracy</td><td>0.943</td></tr><tr><td>test/weak_loss</td><td>1.39338</td></tr><tr><td>train/illegal_move_chance</td><td>0.07303</td></tr><tr><td>train/random_loss</td><td>1.38673</td></tr><tr><td>train/strong_accuracy</td><td>0.674</td></tr><tr><td>train/strong_loss</td><td>1.37177</td></tr><tr><td>train/weak_accuracy</td><td>0.948</td></tr><tr><td>train/weak_loss</td><td>1.38673</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment_huge_weak_2025-03-05-12-19</strong> at: <a href='https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground/runs/wd4n41bn' target=\"_blank\">https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground/runs/wd4n41bn</a><br> View project at: <a href='https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground' target=\"_blank\">https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250305_121905-wd4n41bn/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving model to device:  cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250305_121939-04wpa68b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground/runs/04wpa68b' target=\"_blank\">experiment_huge_weak_2025-03-05-12-19</a></strong> to <a href='https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground' target=\"_blank\">https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground/runs/04wpa68b' target=\"_blank\">https://wandb.ai/benwilop-rwth-aachen-university/tictactoe_playground/runs/04wpa68b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7a591f3b841406a9ae4981373a82f98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training batches:   0%|          | 0/3190 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b72874f4af934329a17ad9ff8219f20a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def run_full_training(project_name, model_size: str, goal: Goal, train_data, test_data, training_cfg: dict, model_cfg: dict) -> None:\n",
        "    lr = training_cfg.get(\"learning_rate\")\n",
        "    weight_decay = training_cfg.get(\"weight_decay\")\n",
        "    epochs = training_cfg.get(\"epochs\")\n",
        "    batch_size = training_cfg.get(\"batch_size\")\n",
        "\n",
        "    model = HookedTransformer(model_cfg).to(model_cfg.device)\n",
        "    loss_fn = cross_entropy\n",
        "    optimizer =  t.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    wandb.finish()  # In case previous run did not get finished\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
        "    experiment_name = f\"experiment_{model_size}_{str(goal)}_{timestamp}\"\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=experiment_name,\n",
        "        config = {\n",
        "            \"transformer_config\": model_cfg.to_dict(),\n",
        "            \"learning_rate\": lr,\n",
        "            \"weight_decay\": weight_decay,\n",
        "            \"test_train_split\": len(train_data.games_data) / (len(train_data.games_data) + len(test_data.games_data)),\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "        })\n",
        "    run_id = wandb.run.id\n",
        "    train_model(project_name, experiment_name, timestamp,\n",
        "        model, goal, optimizer, loss_fn,\n",
        "        train_data, test_data, training_cfg.get(\"epochs\"), batch_size=batch_size)\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "    return model, experiment_name, run_id\n",
        "\n",
        "print(tictactoe_train_data.random_move_labels.shape)\n",
        "project_name = \"tictactoe_playground\"\n",
        "model_size = \"huge\"\n",
        "model_cfg = get_model_config(model_size)\n",
        "wandb.finish()\n",
        "model, _, _ = run_full_training(project_name, model_size, Goal.WEAK_GOAL, tictactoe_train_data, tictactoe_test_data, training_cfg, model_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAaYTgtQxkqc"
      },
      "outputs": [],
      "source": [
        "def save_model(model, run_id, project_name: str, experiment_name: str, experiment_folder: str) -> None:\n",
        "    project_dir = f\"{experiment_folder}/{project_name}\"\n",
        "    if project_dir not in sys.path:\n",
        "        sys.path.append(project_dir)\n",
        "    os.makedirs(project_dir, exist_ok=True)\n",
        "\n",
        "    file_name = f\"{experiment_name}_{run_id}.pkl\"\n",
        "    file_path = os.path.join(project_dir, file_name)\n",
        "\n",
        "    assert not os.path.exists(file_path)\n",
        "    t.save(model, file_path)\n",
        "    print(f\"Model saved to {file_path}\")\n",
        "\n",
        "\n",
        "def load_model_get_matching_files(project_name: str, model_size: str, goal: Goal, experiment_folder: str):\n",
        "    project_dir = f\"{experiment_folder}/{project_name}\"\n",
        "    experiment_prefix = f\"experiment_{model_size}_{str(goal)}_\"\n",
        "    pattern = os.path.join(project_dir, experiment_prefix + \"*.pkl\")\n",
        "    matching_files = glob.glob(pattern)\n",
        "    return matching_files\n",
        "\n",
        "\n",
        "def load_model(project_name: str, model_size: str, goal: Goal, experiment_folder: str) -> t.nn.Module:\n",
        "    matching_files = load_model_get_matching_files(project_name, model_size, goal, experiment_folder)\n",
        "\n",
        "    if not matching_files:\n",
        "        print(f\"No model files found for size {model_size} and goal {goal}\")\n",
        "        return None\n",
        "\n",
        "    # Pick the most recent file based on modification time.\n",
        "    latest_file = max(matching_files, key=os.path.getmtime)\n",
        "    print(f\"Loading model from {latest_file}\")\n",
        "    model = t.load(latest_file)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtXdvXujjy_Z"
      },
      "source": [
        "### Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp_ENvvSiLF3"
      },
      "outputs": [],
      "source": [
        "def pretrain_models(experiment_folder:str, project_name: str, tictactoe_train_data, tictactoe_test_data, training_cfg) -> None:\n",
        "    for model_size in [\"tiny\", \"small\", \"medium\", \"large\", \"huge\", \"gigantic\"]:\n",
        "        for goal in [Goal.WEAK_GOAL, Goal.STRONG_GOAL]:\n",
        "            matching_files = load_model_get_matching_files(project_name, model_size, goal, experiment_folder)\n",
        "            if not matching_files:\n",
        "                adapted_training_cfg = deepcopy(training_cfg)\n",
        "\n",
        "                model_size_to_epochs = {\n",
        "                    \"tiny\": 50,\n",
        "                    \"small\": 30,\n",
        "                    \"medium\": 20,\n",
        "                    \"large\": 5,\n",
        "                    \"huge\": 3,\n",
        "                    \"gigantic\": 2\n",
        "                }\n",
        "                adapted_training_cfg[\"epochs\"] = model_size_to_epochs[model_size]\n",
        "\n",
        "                model_cfg = get_model_config(model_size)\n",
        "                model, experiment_name, run_id = run_full_training(project_name, model_size, goal, tictactoe_train_data, tictactoe_test_data, adapted_training_cfg, model_cfg)\n",
        "                save_model(model, run_id, project_name, experiment_name, experiment_folder)\n",
        "                model.cpu()\n",
        "                del model\n",
        "                t.cuda.empty_cache()\n",
        "\n",
        "# experiment_folder = \"/content/drive/MyDrive/WSG_games/Experiments\"\n",
        "# project_name = \"tictactoe_pretrained_different_epochs\"\n",
        "# project_name = \"tictactoe_pretrained_one_hot_labels\"\n",
        "# pretrain_models(experiment_folder, project_name, tictactoe_train_data, tictactoe_test_data, training_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UammRfNkGPt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_pretrain_models(experiment_folder, project_name, test_data):\n",
        "    minimal_loss_weak = 0.4463610351085663\n",
        "    minimal_loss_strong = 0.23728151619434357\n",
        "\n",
        "    # Initialize dictionaries to store the data for each goal type.\n",
        "    data_by_goal = {\n",
        "        Goal.WEAK_GOAL: {\n",
        "            \"params\": [],\n",
        "            \"random_loss\": [],\n",
        "            \"weak_loss\": [],\n",
        "            \"strong_loss\": []\n",
        "        },\n",
        "        Goal.STRONG_GOAL: {\n",
        "            \"params\": [],\n",
        "            \"random_loss\": [],\n",
        "            \"weak_loss\": [],\n",
        "            \"strong_loss\": []\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Iterate over model sizes and both goal types.\n",
        "    for model_size in [\"tiny\", \"small\", \"medium\", \"large\", \"huge\", \"gigantic\"]:\n",
        "        for goal in [Goal.WEAK_GOAL, Goal.STRONG_GOAL]:\n",
        "            model = load_model(project_name, model_size, goal, experiment_folder)\n",
        "            if not model:\n",
        "                continue\n",
        "\n",
        "            # Evaluate\n",
        "            n_parameters = count_parameters(model)\n",
        "            test_sample = random_sample_tictactoe_data(test_data, 1000)\n",
        "            test_logits = model(test_sample.games_data)\n",
        "            random_loss = cross_entropy(test_logits, test_sample.random_move_labels).item()\n",
        "            weak_loss   = cross_entropy(test_logits, test_sample.weak_goals_labels).item()\n",
        "            strong_loss = cross_entropy(test_logits, test_sample.strong_goals_labels).item()\n",
        "\n",
        "            # Save the computed values in the appropriate goal category\n",
        "            data_by_goal[goal][\"params\"].append(n_parameters)\n",
        "            data_by_goal[goal][\"random_loss\"].append(random_loss)\n",
        "            data_by_goal[goal][\"weak_loss\"].append(weak_loss)\n",
        "            data_by_goal[goal][\"strong_loss\"].append(strong_loss)\n",
        "\n",
        "            model.cpu()\n",
        "            del model\n",
        "            t.cuda.empty_cache()\n",
        "\n",
        "    # Create a figure with two subplots (side-by-side)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "    # Plot for models with WEAK_GOAL\n",
        "    ax = axes[0]\n",
        "    ax.plot(data_by_goal[Goal.WEAK_GOAL][\"params\"], data_by_goal[Goal.WEAK_GOAL][\"random_loss\"], 'o-', label=\"Random CE Loss\")\n",
        "    ax.plot(data_by_goal[Goal.WEAK_GOAL][\"params\"], data_by_goal[Goal.WEAK_GOAL][\"weak_loss\"], 's-', label=\"Weak CE Loss\")\n",
        "    ax.plot(data_by_goal[Goal.WEAK_GOAL][\"params\"], data_by_goal[Goal.WEAK_GOAL][\"strong_loss\"], 'd-', label=\"Strong CE Loss\")\n",
        "    ax.axhline(y=minimal_loss_weak, color='gray', linestyle='--', label=\"Min Achievable Weak Loss\")\n",
        "\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_ylim(0, 6.5)\n",
        "    ax.set_xlabel(\"Number of Parameters (log scale)\")\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.set_title(\"Loss vs. Params (Goal: WEAK_GOAL)\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    # Plot for models with STRONG_GOAL\n",
        "    ax = axes[1]\n",
        "    ax.plot(data_by_goal[Goal.STRONG_GOAL][\"params\"], data_by_goal[Goal.STRONG_GOAL][\"random_loss\"], 'o-', label=\"Random CE Loss\")\n",
        "    ax.plot(data_by_goal[Goal.STRONG_GOAL][\"params\"], data_by_goal[Goal.STRONG_GOAL][\"weak_loss\"], 's-', label=\"Weak CE Loss\")\n",
        "    ax.plot(data_by_goal[Goal.STRONG_GOAL][\"params\"], data_by_goal[Goal.STRONG_GOAL][\"strong_loss\"], 'd-', label=\"Strong CE Loss\")\n",
        "    ax.axhline(y=minimal_loss_strong, color='gray', linestyle='--', label=\"Min Achievable StrongLoss\")\n",
        "\n",
        "    ax.set_xscale('log')\n",
        "    ax.set_ylim(0, 6.5)\n",
        "    ax.set_xlabel(\"Number of Parameters (log scale)\")\n",
        "    ax.set_ylabel(\"Loss\")\n",
        "    ax.set_title(\"Loss vs. Params (Goal: STRONG_GOAL)\")\n",
        "    ax.legend()\n",
        "    ax.grid(True, which=\"both\", ls=\"--\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# plot_loss_pretrain_models(experiment_folder, project_name, tictactoe_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPjvE4hh3tGO"
      },
      "outputs": [],
      "source": [
        "raise Exception()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWJYhJRxx2I-"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_finetuning(model, train_data, test_data, loss_fn, epoch, n_samples=1000):\n",
        "    train_sample = random_sample_tictactoe_data(train_data, n_samples)\n",
        "    test_sample  = random_sample_tictactoe_data(test_data, n_samples)\n",
        "\n",
        "    model.eval()\n",
        "    with t.no_grad():\n",
        "        train_logits = model(train_sample.games_data)\n",
        "        test_logits  = model(test_sample.games_data)\n",
        "        train_loss = loss_fn(train_logits, train_sample.weak_goals_labels).item()\n",
        "        test_loss  = loss_fn(test_logits, test_sample.weak_goals_labels).item()\n",
        "\n",
        "    wandb.log({\n",
        "        \"finetune/train\": train_loss,\n",
        "        \"finetune/test\": test_loss,\n",
        "    })\n",
        "\n",
        "\n",
        "def finetune_strong_with_weak(project_name, experiment_name, weak_model, strong_model, train_data, test_data, training_cfg: dict):\n",
        "    lr = training_cfg.get(\"learning_rate\")\n",
        "    weight_decay = training_cfg.get(\"weight_decay\")\n",
        "    epochs = training_cfg.get(\"epochs\")\n",
        "    batch_size = training_cfg.get(\"batch_size\")\n",
        "\n",
        "    # Compute weak labels using weak_model predictions\n",
        "    weak_model.eval()\n",
        "    with t.no_grad():\n",
        "        train_logits = weak_model(train_data.games_data)\n",
        "        train_weak_labels = softmax(train_logits, dim=-1)  # t.argmax(train_logits, dim=-1)\n",
        "        test_logits = weak_model(test_data.games_data)\n",
        "        test_weak_labels = softmax(test_logits, dim=-1)  # t.argmax(test_logits, dim=-1)\n",
        "\n",
        "    train_dataset = TensorDataset(train_data.games_data, train_weak_labels)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    loss_fn = cross_entropy\n",
        "    optimizer =  t.optim.AdamW(strong_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    wandb.finish()  # in case a previous run is still active\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=experiment_name,\n",
        "        config={\n",
        "            \"learning_rate\": lr,\n",
        "            \"weight_decay\": weight_decay,\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": batch_size\n",
        "        }\n",
        "    )\n",
        "    run_id = wandb.run.id\n",
        "\n",
        "    # Finetuning loop: train strong_model to match the weak_model predictions\n",
        "    log_generating_game_wandb(strong_model)\n",
        "    evaluate_model(strong_model, train_data, test_data, loss_fn)\n",
        "    evaluate_model_finetuning(strong_model, train_data, test_data, loss_fn, 0)\n",
        "    n_datapoints_since_last_evaluation = 0\n",
        "    n_datapoints_since_last_generation_evaluation = 0\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training epochs\", position=0, dynamic_ncols=True):\n",
        "        # -------------------------\n",
        "        # Training Phase (mini-batch loop)\n",
        "        # -------------------------\n",
        "        strong_model.train()\n",
        "        for games, labels in tqdm(train_loader, desc=\"Training batches\", leave=False, position=1, dynamic_ncols=True):\n",
        "            optimizer.zero_grad()\n",
        "            logits = strong_model(games)\n",
        "            loss = loss_fn(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            n_datapoints_since_last_evaluation += batch_size\n",
        "            if n_datapoints_since_last_evaluation > 1000:\n",
        "                n_datapoints_since_last_evaluation = 0\n",
        "                evaluate_model(strong_model, train_data, test_data, loss_fn)\n",
        "                evaluate_model_finetuning(strong_model, train_data, test_data, loss_fn, epoch)\n",
        "\n",
        "            n_datapoints_since_last_generation_evaluation += batch_size\n",
        "            if n_datapoints_since_last_generation_evaluation > 10000:\n",
        "                n_datapoints_since_last_generation_evaluation = 0\n",
        "                log_generating_game_wandb(strong_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fER3-VgSv1nU"
      },
      "outputs": [],
      "source": [
        "def _quick_evaluation(name, model, test_data):\n",
        "    model.eval()\n",
        "    with t.no_grad():\n",
        "        test_sample = random_sample_tictactoe_data(test_data, 1000)\n",
        "        test_logits = model(test_sample.games_data)\n",
        "        weak_loss   = cross_entropy(test_logits, test_sample.weak_goals_labels).item()\n",
        "        strong_loss = cross_entropy(test_logits, test_sample.strong_goals_labels).item()\n",
        "        print(name)\n",
        "        print(\"weak_loss: \", weak_loss)\n",
        "        print(\"strong_loss: \", strong_loss)\n",
        "\n",
        "# experiment_folder = \"/content/drive/MyDrive/WSG_games/Experiments\"\n",
        "# project_name = \"tictactoe_pretrained_different_epochs\"\n",
        "# weak_model_weak_goals = load_model(project_name, \"small\", Goal.WEAK_GOAL, experiment_folder)\n",
        "# strong_model_weak_goals = load_model(project_name, \"medium\", Goal.WEAK_GOAL, experiment_folder)\n",
        "# strong_model_strong_goals = load_model(project_name, \"medium\", Goal.STRONG_GOAL, experiment_folder)\n",
        "# _quick_evaluation(\"Weak model weak goal\", weak_model_weak_goals, tictactoe_test_data)\n",
        "# _quick_evaluation(\"Strong model weak goal\", strong_model_weak_goals, tictactoe_test_data)\n",
        "# _quick_evaluation(\"Strong model strong goal\", strong_model_strong_goals, tictactoe_test_data)\n",
        "# strong_model_finetuned = deepcopy(strong_model_strong_goals)\n",
        "\n",
        "# adapted_training_cfg = deepcopy(training_cfg)\n",
        "# adapted_training_cfg[\"epochs\"] = 20\n",
        "\n",
        "# project_name = \"tictactoe_playground\"\n",
        "# timestamp = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
        "# experiment_name = f\"experiment_finetuning_{timestamp}\"\n",
        "# finetune_strong_with_weak(project_name, experiment_name, weak_model_weak_goals, strong_model_finetuned, tictactoe_train_data, tictactoe_test_data, adapted_training_cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHXq7Cck4kZu"
      },
      "outputs": [],
      "source": [
        "# _quick_evaluation(\"Weak model weak goal\", weak_model_weak_goals, tictactoe_test_data)\n",
        "# _quick_evaluation(\"Strong model weak goal\", strong_model_weak_goals, tictactoe_test_data)\n",
        "# _quick_evaluation(\"Strong model strong goal\", strong_model_strong_goals, tictactoe_test_data)\n",
        "# _quick_evaluation(\"Strong model weakly-finetuned to weak goal\", strong_model_finetuned, tictactoe_test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TAZfSRM_vTL"
      },
      "source": [
        "# Inspect model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yivIGoeLfeFx"
      },
      "outputs": [],
      "source": [
        "from wsg_games.tictactoe.evals import *\n",
        "from wsg_games.tictactoe.data import *\n",
        "from wsg_games.tictactoe.game import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FseGnVqe_00c"
      },
      "outputs": [],
      "source": [
        "# experiment_folder = \"/content/drive/MyDrive/WSG_games/Experiments\"\n",
        "# project_name = \"tictactoe_pretrained_different_epochs\"\n",
        "# model = load_model(project_name, \"medium\", Goal.WEAK_GOAL, experiment_folder)\n",
        "# _quick_evaluation(\"model weak goal\", model, tictactoe_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pMmX7Y7_zLG"
      },
      "outputs": [],
      "source": [
        "W = model.embed.W_E\n",
        "W_normed = W / W.norm(dim=1, keepdim=True)\n",
        "\n",
        "# Compute cosine similarity matrix and move to CPU as a NumPy array\n",
        "cosine_sim = (W_normed @ W_normed.T).detach().cpu().numpy()\n",
        "\n",
        "im = plt.imshow(cosine_sim)\n",
        "plt.title(\"Cosine similarities of each pair of 2D feature embeddings\")\n",
        "plt.gcf().set_size_inches(6, 6)\n",
        "\n",
        "# Add a colorbar with a label\n",
        "cbar = plt.colorbar(im)\n",
        "cbar.set_label(\"Cosine similarity value\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6yflRSMxJKa"
      },
      "outputs": [],
      "source": [
        "W.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCAlprThCL57"
      },
      "outputs": [],
      "source": [
        "board = Board()\n",
        "print(get_best_moves(board, Goal.WEAK_GOAL))\n",
        "board.make_move(1)\n",
        "print(get_best_moves(board, Goal.WEAK_GOAL))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mlqaz9FI6-3"
      },
      "outputs": [],
      "source": [
        "tictactoe_test_data.games_data[600]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FA4fanUYnFCd"
      },
      "outputs": [],
      "source": [
        "tictactoe_test_data.weak_goals_labels[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDmIrkjVnGAI"
      },
      "outputs": [],
      "source": [
        "tictactoe_test_data.games_data[25][:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvZuT97em_5p"
      },
      "outputs": [],
      "source": [
        "softmax(model(tictactoe_test_data.games_data[25][:]), dim=-1).clip(0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0qQ8bpfPAwX"
      },
      "outputs": [],
      "source": [
        "skip_to = 0\n",
        "train_dataset = TensorDataset(\n",
        "    tictactoe_test_data.games_data,\n",
        "    tictactoe_test_data.random_move_labels,\n",
        "    tictactoe_test_data.weak_goals_labels,\n",
        "    tictactoe_test_data.strong_goals_labels,\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
        "i = 0\n",
        "# for games, random_labels, weak_labels, strong_labels in tqdm(train_loader, desc=\"Training batches\", leave=False, position=1, dynamic_ncols=True):\n",
        "#     # if i == 25:\n",
        "#     # print(games)\n",
        "#     logits = model(games)\n",
        "#     # print(logits)\n",
        "#     print(i, cross_entropy(logits, weak_labels))\n",
        "#     # raise Exception()\n",
        "#     i += 1\n",
        "#     if i > 100:\n",
        "#         raise Exception()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmpNzFgly2a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.nn.functional import softmax\n",
        "from dataclasses import dataclass\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.cm import ScalarMappable\n",
        "\n",
        "def visualize_game(data: TicTacToeData, game_id: int, model):\n",
        "    game_moves = data.games_data[game_id]\n",
        "    print(game_moves)\n",
        "\n",
        "    # Build board\n",
        "    board_states = []\n",
        "    board = [''] * 9\n",
        "    current_player = 'X'\n",
        "    for move in game_moves:\n",
        "        if move < 9:\n",
        "            board[move] = current_player\n",
        "            current_player = 'O' if current_player == 'X' else 'X'\n",
        "        board_states.append(board.copy())\n",
        "    n_moves = len(board_states)\n",
        "\n",
        "    model_labels = softmax(model(data.games_data[game_id]), dim=-1)\n",
        "\n",
        "    # Plot\n",
        "    fig, axes = plt.subplots(n_moves, 4, figsize=(16, 4 * n_moves))\n",
        "    if n_moves == 1:\n",
        "        axes = np.expand_dims(axes, 0)\n",
        "\n",
        "    for i in range(n_moves - 1):\n",
        "        # Get data\n",
        "        current_state = board_states[i]\n",
        "\n",
        "        # Get labels\n",
        "        model_label = model_labels[:, i, :]\n",
        "        random_label = data.random_move_labels[game_id, i, :]\n",
        "        weak_label = data.weak_goals_labels[game_id, i, :]\n",
        "        strong_label = data.strong_goals_labels[game_id, i, :]\n",
        "        distributions = [\n",
        "            model_label,\n",
        "            random_label,\n",
        "            weak_label,\n",
        "            strong_label\n",
        "        ]\n",
        "        titles = ['Model Output', 'Random Label', 'Weak Goal Label', 'Strong Goal Label']\n",
        "\n",
        "        # Plot\n",
        "        for j, (dist, title_prefix) in enumerate(zip(distributions, titles)):\n",
        "            ax = axes[i, j]\n",
        "            dist = dist.detach().cpu().numpy().flatten()\n",
        "            board_grid = dist[:9].reshape(3, 3)\n",
        "            end_game_prob = dist[9]\n",
        "\n",
        "            # Color map\n",
        "            im = ax.imshow(board_grid, vmin=0, vmax=1, cmap='viridis')\n",
        "            ax.set_title(f\"{title_prefix} (End-of-game: {end_game_prob:.2f})\")\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "\n",
        "            # Write 'X' and 'O'\n",
        "            for pos, symbol in enumerate(current_state):\n",
        "                if symbol:  # if the cell is occupied\n",
        "                    row, col = divmod(pos, 3)\n",
        "                    ax.text(col, row, symbol, ha='center', va='center',\n",
        "                            fontsize=16, color='white')\n",
        "\n",
        "    # Color legend\n",
        "    norm = mcolors.Normalize(vmin=0, vmax=1)\n",
        "    sm = ScalarMappable(norm=norm, cmap='viridis')\n",
        "    sm.set_array([])\n",
        "    cbar_ax = fig.add_axes([0.95, 0.15, 0.03, 0.7])\n",
        "    fig.colorbar(sm, cax=cbar_ax, orientation='vertical')\n",
        "    plt.tight_layout(rect=[0, 0, 0.93, 1])\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "visualize_game(tictactoe_test_data, game_id=25, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OeILpjRqric"
      },
      "source": [
        "# Sample games"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQb9vhch0H4I"
      },
      "outputs": [],
      "source": [
        "samples = evals.sample_games(model, 1, 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9XukQVE0IL0"
      },
      "outputs": [],
      "source": [
        "evals.eval_model(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-TT_WMvMsLw"
      },
      "outputs": [],
      "source": [
        "sample = samples[1]\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP0nyV-liYvk"
      },
      "outputs": [],
      "source": [
        "from alphatoe.game import Board, State\n",
        "\n",
        "def check(game: list[int]) -> bool:\n",
        "    board = Board()\n",
        "    for move in game[1:-1]:\n",
        "        print(move)\n",
        "        if board.game_state == State.ONGOING:\n",
        "            try:\n",
        "                board.make_move(move)\n",
        "            except:\n",
        "                return True\n",
        "        elif move == 9:\n",
        "            pass\n",
        "        else:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "check(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiWg1vL6aEDi"
      },
      "outputs": [],
      "source": [
        "game.play_game(sample)\n",
        "print(\"\\nPLAY:\")\n",
        "board = game.Board()\n",
        "for move in sample:\n",
        "  if move not in [9, 10]:\n",
        "    board.make_move(move)\n",
        "    board.draw_board()\n",
        "    print(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rhih5yKaYLr"
      },
      "outputs": [],
      "source": [
        "print(evals.model_vs_minimax(model, True), \"\\n\")\n",
        "print(evals._check_minimax_win_rate(model, 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaOr1TOhkhyO"
      },
      "outputs": [],
      "source": [
        "evals.get_error_rate(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii5yV15Lbym4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d19bdd5f4dc24b449367d9097f851c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Commit:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d570db71c3384b25abaf38b9792c0a4f",
            "placeholder": "Enter commit message...",
            "style": "IPY_MODEL_3acc784ecb63411b8aca45d1f0842bcb",
            "value": "Updated Python scripts in Google Colab"
          }
        },
        "d570db71c3384b25abaf38b9792c0a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "70%"
          }
        },
        "3acc784ecb63411b8aca45d1f0842bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87e3c17034aa41bb8ef52596cb5e7b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsModel",
            "_options_labels": [
              "Pull",
              "Push",
              "Pull & Push"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ToggleButtonsView",
            "button_style": "",
            "description": "Action:",
            "description_tooltip": null,
            "disabled": false,
            "icons": [],
            "index": 0,
            "layout": "IPY_MODEL_a690f211f08e4416a841e2fd93fd6d75",
            "style": "IPY_MODEL_1ca2558fdf9d45dfbc7f8e6e2d7d4b39",
            "tooltips": []
          }
        },
        "a690f211f08e4416a841e2fd93fd6d75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca2558fdf9d45dfbc7f8e6e2d7d4b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ToggleButtonsStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ToggleButtonsStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_width": "",
            "description_width": "",
            "font_weight": ""
          }
        },
        "c6a8a272a285403fb8f1daa6209af4e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Run Git Commands üöÄ",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_fcf72a82a1e54f59ad456b175a9c303f",
            "style": "IPY_MODEL_99e5436f186a493ab3e8200b77ff6e84",
            "tooltip": ""
          }
        },
        "fcf72a82a1e54f59ad456b175a9c303f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99e5436f186a493ab3e8200b77ff6e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "179f5f55687f496e90eb069cb44be4d5": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8ecefc0372ab41ae9ad3a1aae7ff871e",
            "msg_id": "",
            "outputs": []
          }
        },
        "8ecefc0372ab41ae9ad3a1aae7ff871e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a591f3b841406a9ae4981373a82f98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1eb62f40f6b45bc826e9cb28d4269eb",
              "IPY_MODEL_b66a301ff9874d1da851bf46b7ba4e57",
              "IPY_MODEL_4b3ceb3d0ceb40d1ae528294b6c8b2b2"
            ],
            "layout": "IPY_MODEL_0a147ee180694e1db79d87b85e83b70d"
          }
        },
        "b1eb62f40f6b45bc826e9cb28d4269eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8597b64fc224fec801cd59158f71e59",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b78c21508f74dde97d5641af345e6d0",
            "value": "Training‚Äáepochs:‚Äá‚Äá‚Äá0%"
          }
        },
        "b66a301ff9874d1da851bf46b7ba4e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6898ccd06fc4968a30443a4893a78ea",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3692294d8d347368865021e3f2112d4",
            "value": 0
          }
        },
        "4b3ceb3d0ceb40d1ae528294b6c8b2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bb59ead4e224da9842f3545bd64beb4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ea9ee9fcb6a747319de261191e307699",
            "value": "‚Äá0/10‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "0a147ee180694e1db79d87b85e83b70d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "d8597b64fc224fec801cd59158f71e59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b78c21508f74dde97d5641af345e6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6898ccd06fc4968a30443a4893a78ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3692294d8d347368865021e3f2112d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bb59ead4e224da9842f3545bd64beb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9ee9fcb6a747319de261191e307699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b72874f4af934329a17ad9ff8219f20a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80e3f0edc4b941d7bc9fe12a2db32bbe",
              "IPY_MODEL_93ce3d4eda9f4708b3169dceda073637",
              "IPY_MODEL_ef397fd3d9254e5a866add85caeb6b29"
            ],
            "layout": "IPY_MODEL_78b7a0d6df4c4b76922971f606ef887e"
          }
        },
        "80e3f0edc4b941d7bc9fe12a2db32bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_485cbeffe1834600aa631f1c03fa016a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fb12ed9346ea4051aff80cef91f539d6",
            "value": "Training‚Äábatches:‚Äá‚Äá83%"
          }
        },
        "93ce3d4eda9f4708b3169dceda073637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66dcb91d824f4e9e996870ce7294c642",
            "max": 3190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13ae7ea679db46769e5795b2d4f6b2aa",
            "value": 2632
          }
        },
        "ef397fd3d9254e5a866add85caeb6b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1515c612d93145b3b55dfd8e2ef65903",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_59c9b22f5d8b4257b8184d511b204e08",
            "value": "‚Äá2632/3190‚Äá[02:09&lt;00:25,‚Äá22.20it/s]"
          }
        },
        "78b7a0d6df4c4b76922971f606ef887e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "485cbeffe1834600aa631f1c03fa016a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb12ed9346ea4051aff80cef91f539d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66dcb91d824f4e9e996870ce7294c642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13ae7ea679db46769e5795b2d4f6b2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1515c612d93145b3b55dfd8e2ef65903": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59c9b22f5d8b4257b8184d511b204e08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}